# Nov 25, 2023
# CSC461 – Assignment3 – Machine Learning
# Ch. M. Kashan Akram
# FA21-BSE-066
# Use the dataset file “gender-prediction.csv” available on shared Google Drive folder for this assignment.

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, LeavePOut
from sklearn.metrics import f1_score

data = pd.read_csv('gender-prediction.csv')

#Q1
num_instances = len(data)
print(f"1. Number of instances: {num_instances}")

num_attributes = len(data.columns) - 1
print(f"2. Number of input attributes: {num_attributes}")

output_values = data['gender'].nunique()
print(f"3. Number of possible values in the output attribute: {output_values}")

categorical_attributes = data.select_dtypes(include=['object']).columns
num_categorical_attributes = len(categorical_attributes)
print(f"4. Number of categorical input attributes: {num_categorical_attributes}")

class_ratio = data['gender'].value_counts(normalize=True)
print(f"5. Class ratio (male vs female):\n{class_ratio}")



#Q2
X = data.drop('gender', axis=1)
y = data['gender']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=42)

lr_classifier = LogisticRegression()
lr_classifier.fit(X_train, y_train)
lr_predictions = lr_classifier.predict(X_test)
lr_incorrect_instances = (y_test != lr_predictions).sum()

svm_classifier = SVC()
svm_classifier.fit(X_train, y_train)
svm_predictions = svm_classifier.predict(X_test)
svm_incorrect_instances = (y_test != svm_predictions).sum()

mlp_classifier = MLPClassifier()
mlp_classifier.fit(X_train, y_train)
mlp_predictions = mlp_classifier.predict(X_test)
mlp_incorrect_instances = (y_test != mlp_predictions).sum()

print("Results for 2/3 train and 1/3 test split:")
print(f"Logistic Regression - Incorrect Instances: {lr_incorrect_instances}")
print(f"SVM - Incorrect Instances: {svm_incorrect_instances}")
print(f"MLP - Incorrect Instances: {mlp_incorrect_instances}")

X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X, y, test_size=0.2, random_state=42)

lr_predictions_new = lr_classifier.predict(X_test_new)
lr_incorrect_instances_new = (y_test_new != lr_predictions_new).sum()

svm_predictions_new = svm_classifier.predict(X_test_new)
svm_incorrect_instances_new = (y_test_new != svm_predictions_new).sum()

mlp_predictions_new = mlp_classifier.predict(X_test_new)
mlp_incorrect_instances_new = (y_test_new != mlp_predictions_new).sum()

print("\nResults for 80/20 train and test split:")
print(f"Logistic Regression - Incorrect Instances: {lr_incorrect_instances_new}")
print(f"SVM - Incorrect Instances: {svm_incorrect_instances_new}")
print(f"MLP - Incorrect Instances: {mlp_incorrect_instances_new}")

#Excluding Powerful Attributes
X_powerful_excluded = X.drop(['beard', 'scarf'], axis=1)
X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(X_powerful_excluded, y, test_size=0.2, random_state=42)

lr_classifier_final = LogisticRegression()
lr_classifier_final.fit(X_train_final, y_train_final)
lr_predictions_final = lr_classifier_final.predict(X_test_final)
lr_incorrect_instances_final = (y_test_final != lr_predictions_final).sum()

svm_classifier_final = SVC()
svm_classifier_final.fit(X_train_final, y_train_final)
svm_predictions_final = svm_classifier_final.predict(X_test_final)
svm_incorrect_instances_final = (y_test_final != svm_predictions_final).sum()

mlp_classifier_final = MLPClassifier()
mlp_classifier_final.fit(X_train_final, y_train_final)
mlp_predictions_final = mlp_classifier_final.predict(X_test_final)
mlp_incorrect_instances_final = (y_test_final != mlp_predictions_final).sum()

print("\nResults after excluding the 'powerful' attributes:")
print(f"Logistic Regression - Incorrect Instances: {lr_incorrect_instances_final}")
print(f"SVM - Incorrect Instances: {svm_incorrect_instances_final}")
print(f"MLP - Incorrect Instances: {mlp_incorrect_instances_final}")



#Q3

rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
monte_carlo_f1_scores = cross_val_score(rf_classifier, X, y, cv=5, scoring='f1_macro')

P = 5
leave_p_out = LeavePOut(p=P)
leave_p_out_f1_scores = cross_val_score(rf_classifier, X, y, cv=leave_p_out, scoring='f1_macro')

print(f"Monte Carlo Cross-Validation F1 Scores: {monte_carlo_f1_scores}")
print(f"Leave P-Out Cross-Validation F1 Scores: {leave_p_out_f1_scores}")



#Q4
# Adding 10 new instances (synthetic data)
new_instances = """
72 155 no medium 40 no green female
65 140 yes short 39 yes blue female
68 180 no long 42 yes brown male
69 160 no medium 38 yes gray female
70 145 yes bald 40 no black male
63 130 no short 37 no brown female
71 195 yes medium 43 yes gray male
66 150 no medium 38 no blue male
64 135 no long 37 yes green female
67 170 yes medium 42 no black male
"""

from io import StringIO
new_instances = StringIO(new_instances)

new_data = pd.read_csv(new_instances, sep=' ')
data = data.append(new_data, ignore_index=True)

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_score, recall_score


X = data.drop('gender', axis=1)
y = data['gender']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=10, random_state=42)
model = GaussianNB()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
